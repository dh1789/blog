---
title: "RAG Day 3: ì„ë² ë”©ê³¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ - í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ê¸°"
slug: "rag-day3-embedding-vectordb"
excerpt: "RAG ì‹œìŠ¤í…œì˜ í•µì‹¬ì¸ ì„ë² ë”©ê³¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì•Œì•„ë´…ë‹ˆë‹¤. Voyage AIë¡œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³ , Supabase Vectorì™€ pgvectorë¡œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤."
status: "publish"
categories:
  - "RAG"
  - "AI Development"
tags:
  - "RAG"
  - "ì„ë² ë”©"
  - "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤"
  - "Supabase"
  - "Voyage AI"
  - "pgvector"
language: "ko"
---

## TL;DR

- **ì„ë² ë”©**ì€ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ, RAG ì‹œìŠ¤í…œì˜ ê²€ìƒ‰ í’ˆì§ˆì„ ê²°ì •
- **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤**ëŠ” ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” íŠ¹ìˆ˜ ë°ì´í„°ë² ì´ìŠ¤
- **Voyage AI**ëŠ” ê²€ìƒ‰ ìµœì í™”ëœ ì„ë² ë”© ëª¨ë¸ë¡œ, OpenAI ëŒ€ë¹„ ìš°ìˆ˜í•œ ê²€ìƒ‰ ì„±ëŠ¥ ì œê³µ
- **Supabase Vector**ì™€ **pgvector**ë¡œ PostgreSQL ê¸°ë°˜ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
- **ë°°ì¹˜ ì²˜ë¦¬**ì™€ **ì¤‘ë³µ ê°ì§€**ë¡œ íš¨ìœ¨ì ì¸ ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- GitHub: [my-first-rag](https://github.com/dh1789/my-first-rag)

---

## 1. ì„ë² ë”©ì´ë€? í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ê¸°

### 1.1 ì™œ ì„ë² ë”©ì´ í•„ìš”í•œê°€?

ì»´í“¨í„°ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ë¹„êµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "ì‚¬ê³¼"ì™€ "ì• í”Œ"ì´ ê°™ì€ ì˜ë¯¸ì¸ì§€, "ì€í–‰"ì´ ê¸ˆìœµê¸°ê´€ì¸ì§€ ë‚˜ë¬´ì¸ì§€ ì•Œ ìˆ˜ ì—†ì£ . **ì„ë² ë”©**ì€ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ ê³„ì‚°í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

```typescript
// ì„ë² ë”©ì˜ ê¸°ë³¸ ê°œë…
const text = "RAG ì‹œìŠ¤í…œì€ ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•©ë‹ˆë‹¤";

// ì„ë² ë”© ëª¨ë¸ì„ í†µí•´ ë²¡í„°ë¡œ ë³€í™˜
const vector = await embedder.embed(text);
// ê²°ê³¼: [0.023, -0.041, 0.089, ...] (1024ì°¨ì› ë“±)

// ìœ ì‚¬í•œ ì˜ë¯¸ì˜ í…ìŠ¤íŠ¸ëŠ” ë¹„ìŠ·í•œ ë²¡í„°ë¥¼ ê°€ì§
const similar = "RAGëŠ” retrievalê³¼ generationì„ í•©ì¹œ ê¸°ìˆ ì´ë‹¤";
const similarVector = await embedder.embed(similar);

// ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ë¹„êµ
const similarity = cosineSimilarity(vector, similarVector);
// ê²°ê³¼: 0.92 (ë§¤ìš° ìœ ì‚¬)
```

### 1.2 ì„ë² ë”© ëª¨ë¸ ë¹„êµ

RAG ì‹œìŠ¤í…œì—ì„œ **ì„ë² ë”©** ëª¨ë¸ ì„ íƒì€ ê²€ìƒ‰ í’ˆì§ˆì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ì£¼ìš” **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤** í˜¸í™˜ ì„ë² ë”© ëª¨ë¸ì„ ë¹„êµí•´ë´…ë‹ˆë‹¤.

| ëª¨ë¸ | ì°¨ì› | íŠ¹ì§• | ê°€ê²© (1M í† í°) |
|------|------|------|----------------|
| **Voyage AI voyage-3** | 1024 | ê²€ìƒ‰ ìµœì í™”, ë‹¤êµ­ì–´ ì§€ì› | $0.06 |
| OpenAI text-embedding-3-large | 3072 | ë²”ìš©ì„±, ë†’ì€ ì°¨ì› | $0.13 |
| Cohere embed-v3 | 1024 | ë‹¤êµ­ì–´, ì••ì¶• ì§€ì› | $0.10 |
| OpenAI text-embedding-3-small | 1536 | ì €ë¹„ìš©, ì ë‹¹í•œ ì„±ëŠ¥ | $0.02 |

**Voyage AI**ë¥¼ ì„ íƒí•œ ì´ìœ :
1. ê²€ìƒ‰(retrieval) íƒœìŠ¤í¬ì— ìµœì í™”ëœ **ì„ë² ë”©** ëª¨ë¸
2. í•œêµ­ì–´ í¬í•¨ ë‹¤êµ­ì–´ ì§€ì›
3. í•©ë¦¬ì ì¸ ê°€ê²©
4. RAG ì‹œìŠ¤í…œì— íŠ¹í™”ëœ ì„±ëŠ¥

### 1.3 Voyage AI ì„¤ì •

**Voyage AI**ë¥¼ ì‚¬ìš©í•˜ì—¬ **ì„ë² ë”©**ì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

```typescript
// src/rag/embedders/voyage-embedder.ts
import Anthropic from '@anthropic-ai/sdk';

export interface EmbedderConfig {
  model: string;
  inputType: 'query' | 'document';
}

export class VoyageEmbedder {
  private client: Anthropic;
  private model: string;
  private inputType: 'query' | 'document';

  constructor(config: EmbedderConfig = {
    model: 'voyage-3',
    inputType: 'document'
  }) {
    this.client = new Anthropic();
    this.model = config.model;
    this.inputType = config.inputType;
  }

  async embed(text: string): Promise<number[]> {
    const response = await this.client.messages.create({
      model: this.model,
      max_tokens: 1,
      messages: [{ role: 'user', content: text }],
    });

    // Voyage AIëŠ” ë³„ë„ API ì‚¬ìš©
    const voyageResponse = await fetch('https://api.voyageai.com/v1/embeddings', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.VOYAGE_API_KEY}`,
      },
      body: JSON.stringify({
        model: this.model,
        input: text,
        input_type: this.inputType,
      }),
    });

    const data = await voyageResponse.json();
    return data.data[0].embedding;
  }

  async embedBatch(texts: string[]): Promise<number[][]> {
    const response = await fetch('https://api.voyageai.com/v1/embeddings', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.VOYAGE_API_KEY}`,
      },
      body: JSON.stringify({
        model: this.model,
        input: texts,
        input_type: this.inputType,
      }),
    });

    const data = await response.json();
    return data.data.map((item: { embedding: number[] }) => item.embedding);
  }
}
```

**ì„ë² ë”©** ëª¨ë¸ì˜ `input_type` íŒŒë¼ë¯¸í„°:
- `document`: ì¸ë±ì‹±í•  ë¬¸ì„œìš© (ì €ì¥ ì‹œ)
- `query`: ê²€ìƒ‰ ì¿¼ë¦¬ìš© (ê²€ìƒ‰ ì‹œ)

ì´ êµ¬ë¶„ì´ **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤** ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

---

## 2. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´í•´í•˜ê¸°

### 2.1 ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë€?

**ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤**ëŠ” ê³ ì°¨ì› ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” íŠ¹ìˆ˜ ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. **Voyage AI**ì™€ ê°™ì€ ì„ë² ë”© ëª¨ë¸ë¡œ ìƒì„±í•œ ë²¡í„°ë¥¼ **pgvector** ê°™ì€ í™•ì¥ì„ í†µí•´ ì €ì¥í•©ë‹ˆë‹¤. ê¸°ì¡´ SQL ë°ì´í„°ë² ì´ìŠ¤ì˜ `WHERE` ì¡°ê±´ ëŒ€ì‹ , "ê°€ì¥ ìœ ì‚¬í•œ Nê°œ"ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

```
ì „í†µì  DB: SELECT * FROM docs WHERE category = 'tech'
ë²¡í„° DB:   SELECT * FROM docs ORDER BY similarity(embedding, query_vector) LIMIT 10
```

### 2.2 ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¢…ë¥˜ ë¹„êµ

| ë°ì´í„°ë² ì´ìŠ¤ | íŠ¹ì§• | ì¥ì  | ë‹¨ì  |
|-------------|------|------|------|
| **Supabase Vector** | PostgreSQL + pgvector | ìµìˆ™í•œ SQL, ë¬´ë£Œ í‹°ì–´ | ëŒ€ê·œëª¨ ì‹œ ì„±ëŠ¥ |
| Pinecone | ì™„ì „ ê´€ë¦¬í˜• | í™•ì¥ì„±, ì„±ëŠ¥ | ë¹„ìš©, ë²¤ë” ì¢…ì† |
| Chroma | ë¡œì»¬ ìš°ì„  | ê°„ë‹¨, ë¬´ë£Œ | í”„ë¡œë•ì…˜ í•œê³„ |
| Weaviate | GraphQL ì§€ì› | ìœ ì—°ì„± | ë³µì¡ì„± |
| Qdrant | Rust ê¸°ë°˜ | ë¹ ë¥¸ ì„±ëŠ¥ | ìƒíƒœê³„ |

ì´ ì‹œë¦¬ì¦ˆì—ì„œëŠ” **Supabase Vector**ì™€ **pgvector**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. **Voyage AI** ì„ë² ë”©ê³¼ ì¡°í•©í•˜ë©´ ê°•ë ¥í•œ RAG ê²€ìƒ‰ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- PostgreSQL ê¸°ë°˜ìœ¼ë¡œ ìµìˆ™í•œ SQL ì‚¬ìš©
- ë¬´ë£Œ í‹°ì–´ë¡œ **pgvector** ì‹œì‘ ê°€ëŠ¥
- ë©”íƒ€ë°ì´í„° í•„í„°ë§ ìš©ì´
- SQLê³¼ ë²¡í„° ê²€ìƒ‰ ê²°í•©
- **Voyage AI** ì„ë² ë”©ê³¼ ìµœì  í˜¸í™˜

### 2.3 pgvector ì†Œê°œ

**pgvector**ëŠ” PostgreSQL í™•ì¥ìœ¼ë¡œ, ë²¡í„° ë°ì´í„° íƒ€ì…ê³¼ ìœ ì‚¬ë„ ê²€ìƒ‰ ì—°ì‚°ìë¥¼ ì œê³µí•©ë‹ˆë‹¤.

```sql
-- pgvector í™•ì¥ í™œì„±í™”
CREATE EXTENSION IF NOT EXISTS vector;

-- ë²¡í„° ì»¬ëŸ¼ì´ ìˆëŠ” í…Œì´ë¸” ìƒì„±
CREATE TABLE documents (
  id BIGSERIAL PRIMARY KEY,
  content TEXT NOT NULL,
  embedding VECTOR(1024),  -- 1024ì°¨ì› ë²¡í„°
  metadata JSONB,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± (IVFFlat)
CREATE INDEX ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

**pgvector**ì˜ ê±°ë¦¬ ì—°ì‚°ì:
- `<->`: L2 ê±°ë¦¬ (ìœ í´ë¦¬ë“œ)
- `<#>`: ë‚´ì  (ìŒìˆ˜)
- `<=>`: ì½”ì‚¬ì¸ ê±°ë¦¬ (1 - ìœ ì‚¬ë„)

---

## 3. Supabase Vector ì„¤ì •

### 3.1 Supabase í”„ë¡œì íŠ¸ ìƒì„±

**Supabase**ëŠ” ì˜¤í”ˆì†ŒìŠ¤ Firebase ëŒ€ì•ˆìœ¼ë¡œ, **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤** ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. **Voyage AI** ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ê¸°ì— ìµœì ì…ë‹ˆë‹¤.

1. [supabase.com](https://supabase.com)ì—ì„œ ê³„ì • ìƒì„±
2. ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±
3. í”„ë¡œì íŠ¸ URLê³¼ API í‚¤ ë³µì‚¬

```bash
# .env
SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
SUPABASE_SERVICE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

### 3.2 ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ì •

**Supabase** SQL ì—ë””í„°ì—ì„œ ì‹¤í–‰:

```sql
-- pgvector í™•ì¥ í™œì„±í™”
CREATE EXTENSION IF NOT EXISTS vector;

-- ë¬¸ì„œ ì²­í¬ í…Œì´ë¸”
CREATE TABLE document_chunks (
  id BIGSERIAL PRIMARY KEY,
  content TEXT NOT NULL,
  embedding VECTOR(1024),
  metadata JSONB DEFAULT '{}',
  source TEXT,
  chunk_index INTEGER,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- ë²¡í„° ê²€ìƒ‰ìš© ì¸ë±ìŠ¤
CREATE INDEX document_chunks_embedding_idx ON document_chunks
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ìš© ì¸ë±ìŠ¤
CREATE INDEX document_chunks_metadata_idx ON document_chunks
USING gin (metadata);

-- ì†ŒìŠ¤ë³„ ê²€ìƒ‰ìš© ì¸ë±ìŠ¤
CREATE INDEX document_chunks_source_idx ON document_chunks (source);

-- ìœ ì‚¬ë„ ê²€ìƒ‰ í•¨ìˆ˜
CREATE OR REPLACE FUNCTION match_documents(
  query_embedding VECTOR(1024),
  match_count INT DEFAULT 5,
  filter JSONB DEFAULT '{}'
)
RETURNS TABLE (
  id BIGINT,
  content TEXT,
  metadata JSONB,
  source TEXT,
  similarity FLOAT
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    dc.id,
    dc.content,
    dc.metadata,
    dc.source,
    1 - (dc.embedding <=> query_embedding) AS similarity
  FROM document_chunks dc
  WHERE dc.metadata @> filter
  ORDER BY dc.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;
```

### 3.3 Supabase í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„

**Supabase**ì™€ ì—°ë™í•˜ëŠ” **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤** í´ë¼ì´ì–¸íŠ¸:

```typescript
// src/rag/stores/supabase-store.ts
import { createClient, SupabaseClient } from '@supabase/supabase-js';

export interface DocumentRecord {
  id?: number;
  content: string;
  embedding: number[];
  metadata: Record<string, unknown>;
  source: string;
  chunk_index: number;
}

export interface SearchResult {
  id: number;
  content: string;
  metadata: Record<string, unknown>;
  source: string;
  similarity: number;
}

export class SupabaseVectorStore {
  private client: SupabaseClient;

  constructor() {
    this.client = createClient(
      process.env.SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_KEY!
    );
  }

  async upsert(documents: DocumentRecord[]): Promise<void> {
    const { error } = await this.client
      .from('document_chunks')
      .upsert(
        documents.map(doc => ({
          content: doc.content,
          embedding: doc.embedding,
          metadata: doc.metadata,
          source: doc.source,
          chunk_index: doc.chunk_index,
        })),
        { onConflict: 'source,chunk_index' }
      );

    if (error) {
      throw new Error(`Supabase upsert error: ${error.message}`);
    }

    console.log(`âœ… ${documents.length}ê°œ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ`);
  }

  async search(
    queryEmbedding: number[],
    options: {
      topK?: number;
      filter?: Record<string, unknown>;
    } = {}
  ): Promise<SearchResult[]> {
    const { topK = 5, filter = {} } = options;

    const { data, error } = await this.client.rpc('match_documents', {
      query_embedding: queryEmbedding,
      match_count: topK,
      filter: filter,
    });

    if (error) {
      throw new Error(`Supabase search error: ${error.message}`);
    }

    return data as SearchResult[];
  }

  async deleteBySource(source: string): Promise<void> {
    const { error } = await this.client
      .from('document_chunks')
      .delete()
      .eq('source', source);

    if (error) {
      throw new Error(`Supabase delete error: ${error.message}`);
    }

    console.log(`ğŸ—‘ï¸ ì†ŒìŠ¤ "${source}" ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ`);
  }

  async count(): Promise<number> {
    const { count, error } = await this.client
      .from('document_chunks')
      .select('*', { count: 'exact', head: true });

    if (error) {
      throw new Error(`Supabase count error: ${error.message}`);
    }

    return count || 0;
  }
}
```

---

## 4. ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### 4.1 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜

**ì„ë² ë”©**ê³¼ **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤**ë¥¼ ê²°í•©í•œ ì™„ì „í•œ ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸:

```
ë¬¸ì„œ â†’ ì²­í‚¹ â†’ ì„ë² ë”© â†’ ë²¡í„° DB ì €ì¥
  â†“       â†“        â†“          â†“
 PDF    RecursiveChunker  VoyageAI  Supabase
 MD     FixedSizeChunker  OpenAI    Pinecone
 Web                      Cohere    Chroma
```

### 4.2 ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ êµ¬í˜„

Day 2ì˜ ì²­í‚¹ê³¼ ì˜¤ëŠ˜ì˜ **ì„ë² ë”©**, **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤**ë¥¼ í†µí•©:

```typescript
// src/rag/pipeline/indexing-pipeline.ts
import { DocumentLoader } from '../loaders/document-loader';
import { RecursiveChunker } from '../chunkers/recursive-chunker';
import { VoyageEmbedder } from '../embedders/voyage-embedder';
import { SupabaseVectorStore, DocumentRecord } from '../stores/supabase-store';

export interface IndexingConfig {
  chunkSize: number;
  chunkOverlap: number;
  batchSize: number;
}

export class IndexingPipeline {
  private loader: DocumentLoader;
  private chunker: RecursiveChunker;
  private embedder: VoyageEmbedder;
  private store: SupabaseVectorStore;
  private batchSize: number;

  constructor(config: IndexingConfig = {
    chunkSize: 512,
    chunkOverlap: 50,
    batchSize: 100
  }) {
    this.loader = new DocumentLoader();
    this.chunker = new RecursiveChunker(config.chunkSize);
    this.embedder = new VoyageEmbedder({ model: 'voyage-3', inputType: 'document' });
    this.store = new SupabaseVectorStore();
    this.batchSize = config.batchSize;
  }

  async index(sources: string[]): Promise<void> {
    console.log(`ğŸ“š ì¸ë±ì‹± ì‹œì‘: ${sources.length}ê°œ ì†ŒìŠ¤`);

    for (const source of sources) {
      await this.indexSource(source);
    }

    const totalCount = await this.store.count();
    console.log(`\nâœ… ì¸ë±ì‹± ì™„ë£Œ! ì´ ${totalCount}ê°œ ì²­í¬ ì €ì¥ë¨`);
  }

  private async indexSource(source: string): Promise<void> {
    console.log(`\nğŸ“„ ì²˜ë¦¬ ì¤‘: ${source}`);

    // 1. ë¬¸ì„œ ë¡œë“œ
    const documents = await this.loader.load(source);
    console.log(`  â†’ ${documents.length}ê°œ ë¬¸ì„œ ë¡œë“œ`);

    // 2. ì²­í‚¹
    const allChunks: Array<{ content: string; metadata: Record<string, unknown> }> = [];
    for (const doc of documents) {
      const chunks = this.chunker.chunk(doc);
      allChunks.push(...chunks);
    }
    console.log(`  â†’ ${allChunks.length}ê°œ ì²­í¬ ìƒì„±`);

    // 3. ë°°ì¹˜ë¡œ ì„ë² ë”© ë° ì €ì¥
    for (let i = 0; i < allChunks.length; i += this.batchSize) {
      const batch = allChunks.slice(i, i + this.batchSize);
      const contents = batch.map(c => c.content);

      // ì„ë² ë”© ìƒì„±
      const embeddings = await this.embedder.embedBatch(contents);

      // ì €ì¥ìš© ë ˆì½”ë“œ ìƒì„±
      const records: DocumentRecord[] = batch.map((chunk, idx) => ({
        content: chunk.content,
        embedding: embeddings[idx],
        metadata: chunk.metadata,
        source: source,
        chunk_index: i + idx,
      }));

      // ë²¡í„° DBì— ì €ì¥
      await this.store.upsert(records);

      console.log(`  â†’ ë°°ì¹˜ ${Math.floor(i / this.batchSize) + 1}/${Math.ceil(allChunks.length / this.batchSize)} ì™„ë£Œ`);
    }
  }
}
```

### 4.3 ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

ëŒ€ëŸ‰ì˜ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ë•Œ **ë°°ì¹˜ ì²˜ë¦¬**ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤:

```typescript
// src/rag/utils/batch-processor.ts
export async function processBatch<T, R>(
  items: T[],
  batchSize: number,
  processor: (batch: T[]) => Promise<R[]>,
  options: {
    onProgress?: (completed: number, total: number) => void;
    delayMs?: number;
  } = {}
): Promise<R[]> {
  const { onProgress, delayMs = 100 } = options;
  const results: R[] = [];

  for (let i = 0; i < items.length; i += batchSize) {
    const batch = items.slice(i, i + batchSize);
    const batchResults = await processor(batch);
    results.push(...batchResults);

    if (onProgress) {
      onProgress(Math.min(i + batchSize, items.length), items.length);
    }

    // Rate limiting
    if (i + batchSize < items.length && delayMs > 0) {
      await new Promise(resolve => setTimeout(resolve, delayMs));
    }
  }

  return results;
}
```

### 4.4 ì¤‘ë³µ ê°ì§€ ë° ì²˜ë¦¬

ë™ì¼í•œ ë¬¸ì„œë¥¼ ë‹¤ì‹œ ì¸ë±ì‹±í•  ë•Œ **ì¤‘ë³µ**ì„ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•:

```typescript
// src/rag/utils/deduplication.ts
import crypto from 'crypto';

export function generateContentHash(content: string): string {
  return crypto.createHash('sha256').update(content).digest('hex').slice(0, 16);
}

export class DeduplicationManager {
  private seenHashes: Set<string> = new Set();

  isDuplicate(content: string): boolean {
    const hash = generateContentHash(content);
    if (this.seenHashes.has(hash)) {
      return true;
    }
    this.seenHashes.add(hash);
    return false;
  }

  reset(): void {
    this.seenHashes.clear();
  }
}
```

**Supabase**ì—ì„œ ì¤‘ë³µ ì²˜ë¦¬:

```sql
-- ì†ŒìŠ¤ì™€ ì²­í¬ ì¸ë±ìŠ¤ë¡œ ìœ ë‹ˆí¬ ì œì•½
ALTER TABLE document_chunks
ADD CONSTRAINT unique_source_chunk
UNIQUE (source, chunk_index);
```

---

## 5. ì‹¤ìŠµ: ì™„ì „í•œ ì¸ë±ì‹± ì˜ˆì œ

### 5.1 í”„ë¡œì íŠ¸ ì„¤ì •

```bash
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
npm install @supabase/supabase-js dotenv

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
echo "VOYAGE_API_KEY=your-voyage-key" >> .env
echo "SUPABASE_URL=https://xxx.supabase.co" >> .env
echo "SUPABASE_SERVICE_KEY=your-service-key" >> .env
```

### 5.2 ì‚¬ìš© ì˜ˆì œ

```typescript
// examples/day3-indexing-demo.ts
import { IndexingPipeline } from '../src/rag/pipeline/indexing-pipeline';
import { VoyageEmbedder } from '../src/rag/embedders/voyage-embedder';
import { SupabaseVectorStore } from '../src/rag/stores/supabase-store';
import 'dotenv/config';

async function main() {
  // 1. ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¬¸ì„œ ì €ì¥
  const pipeline = new IndexingPipeline({
    chunkSize: 512,
    chunkOverlap: 50,
    batchSize: 50,
  });

  await pipeline.index([
    './documents/company-policy.pdf',
    './documents/product-guide.md',
  ]);

  // 2. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
  const embedder = new VoyageEmbedder({
    model: 'voyage-3',
    inputType: 'query',  // ê²€ìƒ‰ìš©
  });
  const store = new SupabaseVectorStore();

  const query = "íœ´ê°€ ì •ì±…ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”";
  const queryEmbedding = await embedder.embed(query);

  const results = await store.search(queryEmbedding, {
    topK: 5,
    filter: { category: 'HR' },
  });

  console.log('\nğŸ” ê²€ìƒ‰ ê²°ê³¼:');
  results.forEach((result, i) => {
    console.log(`\n[${i + 1}] ìœ ì‚¬ë„: ${result.similarity.toFixed(3)}`);
    console.log(`    ì†ŒìŠ¤: ${result.source}`);
    console.log(`    ë‚´ìš©: ${result.content.slice(0, 100)}...`);
  });
}

main().catch(console.error);
```

### 5.3 ì‹¤í–‰ ê²°ê³¼

```
ğŸ“š ì¸ë±ì‹± ì‹œì‘: 2ê°œ ì†ŒìŠ¤

ğŸ“„ ì²˜ë¦¬ ì¤‘: ./documents/company-policy.pdf
  â†’ 15ê°œ ë¬¸ì„œ ë¡œë“œ
  â†’ 45ê°œ ì²­í¬ ìƒì„±
  â†’ ë°°ì¹˜ 1/1 ì™„ë£Œ

ğŸ“„ ì²˜ë¦¬ ì¤‘: ./documents/product-guide.md
  â†’ 8ê°œ ë¬¸ì„œ ë¡œë“œ
  â†’ 24ê°œ ì²­í¬ ìƒì„±
  â†’ ë°°ì¹˜ 1/1 ì™„ë£Œ

âœ… ì¸ë±ì‹± ì™„ë£Œ! ì´ 69ê°œ ì²­í¬ ì €ì¥ë¨

ğŸ” ê²€ìƒ‰ ê²°ê³¼:

[1] ìœ ì‚¬ë„: 0.892
    ì†ŒìŠ¤: ./documents/company-policy.pdf
    ë‚´ìš©: ì—°ì°¨ íœ´ê°€ëŠ” ì…ì‚¬ 1ë…„ í›„ë¶€í„° 15ì¼ì´ ë¶€ì—¬ë˜ë©°, ê·¼ì† ì—°ìˆ˜ì— ë”°ë¼ ì¶”ê°€ë©ë‹ˆë‹¤...

[2] ìœ ì‚¬ë„: 0.845
    ì†ŒìŠ¤: ./documents/company-policy.pdf
    ë‚´ìš©: ë³‘ê°€ëŠ” ì§„ë‹¨ì„œ ì œì¶œ ì‹œ ì—°ê°„ 30ì¼ê¹Œì§€ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤...
```

---

## 6. ì„ë² ë”© í’ˆì§ˆ í‰ê°€

### 6.1 ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸

**ì„ë² ë”©** ëª¨ë¸ê³¼ **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤** ì„¤ì •ì´ ì˜ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ë°©ë²•:

```typescript
// src/rag/utils/embedding-evaluator.ts
interface EvaluationPair {
  query: string;
  expectedContent: string;  // ê²€ìƒ‰ë˜ì–´ì•¼ í•˜ëŠ” ë‚´ìš©ì˜ ì¼ë¶€
}

export async function evaluateSearchQuality(
  embedder: VoyageEmbedder,
  store: SupabaseVectorStore,
  testPairs: EvaluationPair[]
): Promise<{ accuracy: number; results: Array<{ query: string; found: boolean }> }> {
  const results: Array<{ query: string; found: boolean }> = [];

  for (const pair of testPairs) {
    const queryEmbedding = await embedder.embed(pair.query);
    const searchResults = await store.search(queryEmbedding, { topK: 3 });

    const found = searchResults.some(r =>
      r.content.toLowerCase().includes(pair.expectedContent.toLowerCase())
    );

    results.push({ query: pair.query, found });
  }

  const accuracy = results.filter(r => r.found).length / results.length;

  return { accuracy, results };
}

// ì‚¬ìš© ì˜ˆì‹œ
const evaluation = await evaluateSearchQuality(embedder, store, [
  { query: "íœ´ê°€ëŠ” ë©°ì¹ ?", expectedContent: "15ì¼" },
  { query: "ë³‘ê°€ ì‚¬ìš©ë²•", expectedContent: "ì§„ë‹¨ì„œ" },
  { query: "ì¬íƒê·¼ë¬´ ê°€ëŠ¥?", expectedContent: "ì¬íƒ" },
]);

console.log(`ê²€ìƒ‰ ì •í™•ë„: ${(evaluation.accuracy * 100).toFixed(1)}%`);
```

### 6.2 ì„ë² ë”© ì‹œê°í™”

ê³ ì°¨ì› **ì„ë² ë”©**ì„ 2Dë¡œ ì‹œê°í™”í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë§ í™•ì¸:

```typescript
// t-SNEë‚˜ UMAPìœ¼ë¡œ ì°¨ì› ì¶•ì†Œ í›„ ì‹œê°í™”
// ì‹¤ì œ êµ¬í˜„ì€ Pythonì´ ë” ì í•© (sklearn, plotly)

// TypeScriptì—ì„œëŠ” ê°„ë‹¨í•œ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
function createSimilarityMatrix(embeddings: number[][]): number[][] {
  const n = embeddings.length;
  const matrix: number[][] = [];

  for (let i = 0; i < n; i++) {
    matrix[i] = [];
    for (let j = 0; j < n; j++) {
      matrix[i][j] = cosineSimilarity(embeddings[i], embeddings[j]);
    }
  }

  return matrix;
}

function cosineSimilarity(a: number[], b: number[]): number {
  let dotProduct = 0;
  let normA = 0;
  let normB = 0;

  for (let i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }

  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}
```

---

## 7. ì„±ëŠ¥ ìµœì í™” íŒ

### 7.1 ì„ë² ë”© ìºì‹±

ë™ì¼í•œ í…ìŠ¤íŠ¸ì— ëŒ€í•œ **ì„ë² ë”©** ì¬ìƒì„± ë°©ì§€:

```typescript
// src/rag/cache/embedding-cache.ts
import crypto from 'crypto';

export class EmbeddingCache {
  private cache: Map<string, number[]> = new Map();

  private getKey(text: string, model: string): string {
    const hash = crypto.createHash('md5').update(text).digest('hex');
    return `${model}:${hash}`;
  }

  get(text: string, model: string): number[] | undefined {
    return this.cache.get(this.getKey(text, model));
  }

  set(text: string, model: string, embedding: number[]): void {
    this.cache.set(this.getKey(text, model), embedding);
  }

  has(text: string, model: string): boolean {
    return this.cache.has(this.getKey(text, model));
  }
}
```

### 7.2 ë²¡í„° ì¸ë±ìŠ¤ íŠœë‹

**pgvector**ì˜ IVFFlat ì¸ë±ìŠ¤ ìµœì í™”:

```sql
-- ë°ì´í„° ì–‘ì— ë”°ë¥¸ lists íŒŒë¼ë¯¸í„° ì¡°ì •
-- ê·œì¹™: lists = sqrt(row_count)

-- 1ë§Œ í–‰: lists = 100
-- 10ë§Œ í–‰: lists = 316
-- 100ë§Œ í–‰: lists = 1000

-- ì¸ë±ìŠ¤ ì¬ìƒì„±
DROP INDEX IF EXISTS document_chunks_embedding_idx;
CREATE INDEX document_chunks_embedding_idx ON document_chunks
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 316);  -- 10ë§Œ í–‰ ê¸°ì¤€

-- ê²€ìƒ‰ ì‹œ probes íŒŒë¼ë¯¸í„° ì¡°ì • (ì •í™•ë„ vs ì†ë„)
SET ivfflat.probes = 10;  -- ê¸°ë³¸ê°’ 1, ë†’ì„ìˆ˜ë¡ ì •í™•í•˜ì§€ë§Œ ëŠë¦¼
```

### 7.3 ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë‹ˆí„°ë§

```sql
-- í…Œì´ë¸” í¬ê¸° í™•ì¸
SELECT
  pg_size_pretty(pg_total_relation_size('document_chunks')) as total_size,
  pg_size_pretty(pg_relation_size('document_chunks')) as table_size,
  pg_size_pretty(pg_indexes_size('document_chunks')) as indexes_size;

-- ì¸ë±ìŠ¤ ì‚¬ìš©ë¥  í™•ì¸
SELECT
  indexrelname,
  idx_scan as scans,
  idx_tup_read as tuples_read,
  idx_tup_fetch as tuples_fetched
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
AND relname = 'document_chunks';
```

---

## 8. ì •ë¦¬ ë° ë‹¤ìŒ í¸ ì˜ˆê³ 

### í•µì‹¬ ë‚´ìš© ì •ë¦¬

ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©:

1. **ì„ë² ë”©**ì€ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í•µì‹¬ ê¸°ìˆ 
2. **Voyage AI**ëŠ” ê²€ìƒ‰ì— ìµœì í™”ëœ **ì„ë² ë”©** ëª¨ë¸
3. **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤**ë¡œ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ ìˆ˜í–‰
4. **Supabase Vector**ì™€ **pgvector**ë¡œ PostgreSQL ê¸°ë°˜ êµ¬ì¶•
5. **ë°°ì¹˜ ì²˜ë¦¬**ì™€ **ì¤‘ë³µ ê°ì§€**ë¡œ íš¨ìœ¨ì  ì¸ë±ì‹±

### Day 4 ì˜ˆê³ : ê²€ìƒ‰ ìµœì í™”ì™€ ë¦¬ë­í‚¹

ë‹¤ìŒ í¸ì—ì„œëŠ” ê²€ìƒ‰ í’ˆì§ˆì„ ë†’ì´ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤:

- ì‹œë§¨í‹± ê²€ìƒ‰ vs í‚¤ì›Œë“œ ê²€ìƒ‰ vs í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
- top-k, ìœ ì‚¬ë„ ì„ê³„ê°’ íŠœë‹
- ë¦¬ë­í‚¹(Reranking)ìœ¼ë¡œ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
- Cohere Rerank í†µí•©

**ì „ì²´ ì½”ë“œëŠ” GitHubì—ì„œ í™•ì¸í•˜ì„¸ìš”:**
[https://github.com/dh1789/my-first-rag](https://github.com/dh1789/my-first-rag)

---

## ì‹œë¦¬ì¦ˆ ë„¤ë¹„ê²Œì´ì…˜

- [Day 1: RAG ê°œë…ê³¼ ì•„í‚¤í…ì²˜](/ko/rag-day1-introduction)
- [Day 2: ë¬¸ì„œ ì²˜ë¦¬ì™€ ì²­í‚¹ ì „ëµ](/ko/rag-day2-document-processing)
- **Day 3: ì„ë² ë”©ê³¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤** (í˜„ì¬ ê¸€)
- [Day 4: ê²€ìƒ‰ ìµœì í™”ì™€ ë¦¬ë­í‚¹](/ko/rag-day4-search-optimization)
- [Day 5: Claude í†µí•©ê³¼ ë‹µë³€ ìƒì„±](/ko/rag-day5-claude-integration)
- [Day 6: í”„ë¡œë•ì…˜ ë°°í¬ì™€ ìµœì í™”](/ko/rag-day6-production)
